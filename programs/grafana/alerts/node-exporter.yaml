namespace: alerts-node-exporter
groups:
  - name: node-exporter
    rules:
      - alert: NodeCPUHighUsage
        expr: |
          sum without(mode) (avg without (cpu) (rate(node_cpu_seconds_total{job=~"integrations/(node_exporter|unix)", mode!~"idle|iowait"}[2m]))) * 100 > 90
        for: 15m
        labels:
          asserts_alert_category: failure
          asserts_entity_type: Node
          asserts_severity: info
          severity: info
        annotations:
          description: |
            CPU usage at {{ $labels.instance }} has been above 90% for the last 15 minutes, is currently at {{ printf "%.2f" $value }}%.
            Note that 'iowait' CPU mode is excluded from total utilization.
          summary: High CPU usage.
      - alert: NodeClockNotSynchronising
        expr: |
          min_over_time(node_timex_sync_status{job=~"integrations/(node_exporter|unix)"}[5m]) == 0
          and
          node_timex_maxerror_seconds{job=~"integrations/(node_exporter|unix)"} >= 16
        for: 10m
        labels:
          asserts_alert_category: failure
          asserts_entity_type: Node
          asserts_severity: warning
          severity: warning
        annotations:
          description: Clock at {{ $labels.instance }} is not synchronising. Ensure NTP is configured on this host.
          summary: Clock not synchronising.
      - alert: NodeClockSkewDetected
        expr: |
          (
            node_timex_offset_seconds{job=~"integrations/(node_exporter|unix)"} > 0.05
          and
            deriv(node_timex_offset_seconds{job=~"integrations/(node_exporter|unix)"}[5m]) >= 0
          )
          or
          (
            node_timex_offset_seconds{job=~"integrations/(node_exporter|unix)"} < -0.05
          and
            deriv(node_timex_offset_seconds{job=~"integrations/(node_exporter|unix)"}[5m]) <= 0
          )
        for: 10m
        labels:
          asserts_alert_category: failure
          asserts_entity_type: Node
          asserts_severity: warning
          severity: warning
        annotations:
          description: Clock at {{ $labels.instance }} is out of sync by more than 0.05s. Ensure NTP is configured correctly on this host.
          summary: Clock skew detected.
      - alert: NodeDiskIOSaturation
        expr: |
          rate(node_disk_io_time_weighted_seconds_total{job=~"integrations/(node_exporter|unix)", device!=""}[5m]) > 10
        for: 30m
        labels:
          asserts_alert_category: failure
          asserts_entity_type: Node
          asserts_severity: warning
          severity: warning
        annotations:
          description: |
            Disk IO queue (aqu-sq) is high on {{ $labels.device }} at {{ $labels.instance }}, has been above 10 for the last 30 minutes, is currently at {{ printf "%.2f" $value }}.
            This symptom might indicate disk saturation.
          summary: Disk IO queue is high.
      - alert: NodeFileDescriptorLimit
        expr: |
          (
            node_filefd_allocated{job=~"integrations/(node_exporter|unix)"} * 100 / node_filefd_maximum{job=~"integrations/(node_exporter|unix)"} > 70
          )
        for: 15m
        labels:
          asserts_alert_category: failure
          asserts_entity_type: Node
          asserts_severity: warning
          severity: warning
        annotations:
          description: File descriptors limit at {{ $labels.instance }} is currently at {{ printf "%.2f" $value }}%.
          summary: Kernel is predicted to exhaust file descriptors limit soon.
      - alert: NodeHasRebooted
        expr: |
          (time() - node_boot_time_seconds{job=~"integrations/(node_exporter|unix)"}) < 600
          and
          (time() - (node_boot_time_seconds{job=~"integrations/(node_exporter|unix)"} offset 10m)) > 600
        labels:
          severity: info
        annotations:
          description: Node {{ $labels.instance }} has rebooted {{ $value | humanize }} seconds ago.
          summary: Node has rebooted.
      - alert: NodeHighNumberConntrackEntriesUsed
        expr: |
          (node_nf_conntrack_entries{job=~"integrations/(node_exporter|unix)"} / node_nf_conntrack_entries_limit) > 0.75
        labels:
          asserts_alert_category: failure
          asserts_entity_type: Node
          asserts_severity: warning
          severity: warning
        annotations:
          description: '{{ $labels.instance }} {{ $value | humanizePercentage }} of conntrack entries are used.'
          summary: Number of conntrack are getting close to the limit.
      - alert: NodeMemoryHighUtilization
        expr: |
          100 - (node_memory_MemAvailable_bytes{job=~"integrations/(node_exporter|unix)"} / node_memory_MemTotal_bytes{job=~"integrations/(node_exporter|unix)"} * 100) > 90
        for: 15m
        labels:
          asserts_alert_category: failure
          asserts_entity_type: Node
          asserts_severity: warning
          severity: warning
        annotations:
          description: |
            Memory is filling up at {{ $labels.instance }}, has been above 90% for the last 15 minutes, is currently at {{ printf "%.2f" $value }}%.
          summary: Host is running out of memory.
      - alert: NodeMemoryMajorPagesFaults
        expr: |
          rate(node_vmstat_pgmajfault{job=~"integrations/(node_exporter|unix)"}[5m]) > 500
        for: 15m
        labels:
          asserts_alert_category: failure
          asserts_entity_type: Node
          asserts_severity: warning
          severity: warning
        annotations:
          description: |
            Memory major pages are occurring at very high rate at {{ $labels.instance }}, 500 major page faults per second for the last 15 minutes, is currently at {{ printf "%.2f" $value }}.
            Please check that there is enough memory available at this instance.
          summary: Memory major page faults are occurring at very high rate.
      - alert: NodeNetworkReceiveErrs
        expr: |
          rate(node_network_receive_errs_total{job=~"integrations/(node_exporter|unix)"}[2m]) / rate(node_network_receive_packets_total{job=~"integrations/(node_exporter|unix)"}[2m]) > 0.01
        for: 1h
        labels:
          asserts_alert_category: failure
          asserts_entity_type: Node
          asserts_severity: warning
          severity: warning
        annotations:
          description: '{{ $labels.instance }} interface {{ $labels.device }} has encountered {{ printf "%.0f" $value }} receive errors in the last two minutes.'
          summary: Network interface is reporting many receive errors.
      - alert: NodeNetworkTransmitErrs
        expr: |
          rate(node_network_transmit_errs_total{job=~"integrations/(node_exporter|unix)"}[2m]) / rate(node_network_transmit_packets_total{job=~"integrations/(node_exporter|unix)"}[2m]) > 0.01
        for: 1h
        labels:
          asserts_alert_category: failure
          asserts_entity_type: Node
          asserts_severity: warning
          severity: warning
        annotations:
          description: '{{ $labels.instance }} interface {{ $labels.device }} has encountered {{ printf "%.0f" $value }} transmit errors in the last two minutes.'
          summary: Network interface is reporting many transmit errors.
      - alert: NodeProcessesCountIsHigh
        expr: |
          node_procs_running{job=~"integrations/(node_exporter|unix)"} > 400
        for: 5m
        labels:
          severity: warning
        annotations:
          description: There is {{ $value }} running processes on {{ $labels.instance }}.
          summary: There is more than 400 running processes on host.
      - alert: NodeRAIDDegraded
        expr: |
          node_md_disks_required{job=~"integrations/(node_exporter|unix)",device!=""} - ignoring (state) (node_md_disks{state="active",job=~"integrations/(node_exporter|unix)",device!=""}) > 0
        for: 15m
        labels:
          asserts_alert_category: failure
          asserts_entity_type: Node
          asserts_severity: critical
          severity: critical
        annotations:
          description: RAID array '{{ $labels.device }}' at {{ $labels.instance }} is in degraded state due to one or more disks failures. Number of spare drives is insufficient to fix issue automatically.
          summary: RAID Array is degraded.
      - alert: NodeRAIDDiskFailure
        expr: |
          node_md_disks{state="failed",job=~"integrations/(node_exporter|unix)",device!=""} > 0
        labels:
          asserts_alert_category: failure
          asserts_entity_type: Node
          asserts_severity: warning
          severity: warning
        annotations:
          description: At least one device in RAID array at {{ $labels.instance }} failed. Array '{{ $labels.device }}' needs attention and possibly a disk swap.
          summary: Failed device in RAID array.
      - alert: NodeSystemSaturation
        expr: |
          node_load1{job=~"integrations/(node_exporter|unix)"}
          / count without (cpu, mode) (node_cpu_seconds_total{job=~"integrations/(node_exporter|unix)", mode="idle"}) > 2
        for: 15m
        labels:
          asserts_alert_category: failure
          asserts_entity_type: Node
          asserts_severity: warning
          severity: warning
        annotations:
          description: |
            System load per core at {{ $labels.instance }} has been above 2 for the last 15 minutes, is currently at {{ printf "%.2f" $value }}.
            This might indicate this instance resources saturation and can cause it becoming unresponsive.
          summary: System saturated, load per core is very high.
      - alert: NodeSystemdServiceCrashlooping
        expr: |
          increase(node_systemd_service_restart_total{job=~"integrations/(node_exporter|unix)"}[5m]) > 2
        for: 15m
        labels:
          asserts_alert_category: failure
          asserts_entity_type: Node
          asserts_severity: warning
          severity: warning
        annotations:
          description: Systemd service {{ $labels.name }} has been restarted too many times at {{ $labels.instance }} for the last 15 minutes. Please check if service is crash looping.
          summary: Systemd service keeps restaring, possibly crash looping.
      - alert: NodeSystemdServiceFailed
        expr: |
          node_systemd_unit_state{job=~"integrations/(node_exporter|unix)", state="failed"} == 1
        for: 5m
        labels:
          asserts_alert_category: failure
          asserts_entity_type: Node
          asserts_severity: warning
          severity: warning
        annotations:
          description: |
            Systemd service {{ $labels.name }} has entered failed state at {{ $labels.instance }}.
            If this service is not required anymore, remove it or run `systemctl reset-failed {{ $labels.name }}` in order to reset the failed counter.
          summary: Systemd service has entered failed state.
      - alert: NodeTextFileCollectorScrapeError
        expr: |
          node_textfile_scrape_error{job=~"integrations/(node_exporter|unix)"} == 1
        labels:
          asserts_alert_category: failure
          asserts_entity_type: Node
          asserts_severity: warning
          severity: warning
        annotations:
          description: Node Exporter text file collector on {{ $labels.instance }} failed to scrape.
          summary: Node Exporter text file collector failed to scrape.
